{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression_tfKeras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4MzsoDr4huuxVn4yErOdw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chewzzz1014/DPhi-Bootcamp/blob/master/notes/deep-learning/LinearRegression_tfKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Machine Learning Model using tensorflow.keras API**"
      ],
      "metadata": {
        "id": "3aH6XoE24aU6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjXgnjeU3srd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Training_set_boston.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0eI0x2dg4n2-",
        "outputId": "4786c593-020f-424d-96dd-e23e246047af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  \\\n",
              "0  15.02340   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  24.0  666.0   \n",
              "1   0.62739   0.0   8.14   0.0  0.5380  5.834  56.5  4.4986   4.0  307.0   \n",
              "2   0.03466  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407   1.0  304.0   \n",
              "3   7.05042   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  24.0  666.0   \n",
              "4   0.72580   0.0   8.14   0.0  0.5380  5.727  69.5  3.7965   4.0  307.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  MEDV  \n",
              "0     20.2  349.48  24.91  12.0  \n",
              "1     21.0  395.62   8.47  19.9  \n",
              "2     16.9  362.25   7.83  19.4  \n",
              "3     20.2    2.52  23.29  13.4  \n",
              "4     21.0  390.95  11.28  18.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eaa84f9b-d0bd-4ec2-8062-33e13c5e9550\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.02340</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6140</td>\n",
              "      <td>5.304</td>\n",
              "      <td>97.3</td>\n",
              "      <td>2.1007</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>349.48</td>\n",
              "      <td>24.91</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.62739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5380</td>\n",
              "      <td>5.834</td>\n",
              "      <td>56.5</td>\n",
              "      <td>4.4986</td>\n",
              "      <td>4.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>395.62</td>\n",
              "      <td>8.47</td>\n",
              "      <td>19.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.03466</td>\n",
              "      <td>35.0</td>\n",
              "      <td>6.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4379</td>\n",
              "      <td>6.031</td>\n",
              "      <td>23.3</td>\n",
              "      <td>6.6407</td>\n",
              "      <td>1.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>16.9</td>\n",
              "      <td>362.25</td>\n",
              "      <td>7.83</td>\n",
              "      <td>19.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.05042</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6140</td>\n",
              "      <td>6.103</td>\n",
              "      <td>85.1</td>\n",
              "      <td>2.0218</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>2.52</td>\n",
              "      <td>23.29</td>\n",
              "      <td>13.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.72580</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5380</td>\n",
              "      <td>5.727</td>\n",
              "      <td>69.5</td>\n",
              "      <td>3.7965</td>\n",
              "      <td>4.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>390.95</td>\n",
              "      <td>11.28</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eaa84f9b-d0bd-4ec2-8062-33e13c5e9550')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eaa84f9b-d0bd-4ec2-8062-33e13c5e9550 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eaa84f9b-d0bd-4ec2-8062-33e13c5e9550');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seperate input features and output feature\n",
        "X = df.drop(\"MEDV\", axis = 1) # input\n",
        "y = df[\"MEDV\"]  # input"
      ],
      "metadata": {
        "id": "j33j9Zp64n7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into train set and test set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80% of data -> train set, 20% of data -> test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "n_features = X.shape[1]\n",
        "print(n_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhMd1g9S4oAT",
        "outputId": "50533662-2272-4666-8c37-40e5ebbfa19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Life Cycle\n",
        "  1. Define Model\n",
        "  2. Compile Model\n",
        "  3. Fit the Model\n",
        "  4. Make Predictions on Test Data\n",
        "  5. Evaluate Model"
      ],
      "metadata": {
        "id": "prEKhuxK6nSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Define Model**\n",
        "  - Select the type of model and choose the architecture or network topology.\n",
        "  - Models can be defined using Sequential API or Functional API.\n",
        "  - `Sequential API` : Simpleset API to get started with Deep Learning. Enables us to create models layer-by-layer\n",
        "  - `Layer` : Group number of neurons together. Holding a collection of neurons, and perform learning process of neural network.\n",
        "  - `ReLU` (rectified linear unit) : Activation function that decides whether or not a neuron should be activated. Defined mathematically as `f(x) = max(0,x)`(x is the output is x >0)."
      ],
      "metadata": {
        "id": "SA-pa1147M8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from numpy.random import seed   #fixes the randomness in neural network\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "\n",
        "# visible layer is defined by \"input_shape\" argument on first hidden layer\n",
        "# first hidden layer\n",
        "model.add(Dense(10, activation = \"relu\", input_shape=(n_features,)))\n",
        "# second hidden layer\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "# third hidden layer\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "LN3SPTR-4opQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Compile Model**\n",
        "    - Select a loss function, eg: mean squared error or cross-entropy, to be optimized.\n",
        "    - Select an algorithm to perform the optimization process. eg: RMSprop\n",
        "    - Select any performance metrics to keep track of during model training process. eg: mean squered error"
      ],
      "metadata": {
        "id": "uEzq5xItBI0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from  tensorflow.keras.optimizers import RMSprop\n",
        "optimizer = RMSprop(0.01)   # 0.01 is learning rate\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=optimizer)"
      ],
      "metadata": {
        "id": "PvSisBaW4otT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Fitting Model**\n",
        "    - Select training configuration (eg: num of epochs [loops thru training set] and batch size[num of samples in each epoch used to estimate model error] )\n",
        "    - Calling a function to perform training process.\n",
        "    - `verbose` : Define how we \"see\" the training progress for each epoch. \n",
        "        - `verbose = 0` : show nothing\n",
        "        - `verbose = 1` : show animated progress bar\n",
        "        - `verbose = 2` : show number of epoch "
      ],
      "metadata": {
        "id": "78QzSyoPC1Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to produce the same result on multiple excution\n",
        "seed_value = 42\n",
        "seed(seed_value)\n",
        "\n",
        "# 1. Set 'PYTHONHASHSEED' environment variable at fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "# 2. Set 'python' built-in pseudo-random generator at fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set 'numpy' psuedo-random generator at fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set 'tensorflow' psuedo-random generator at fixed value\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=30, verbose=1)"
      ],
      "metadata": {
        "id": "F2HO6yrb4oxe",
        "outputId": "33f323c0-a6d5-4fbf-e4f6-582383adc0c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 1s 3ms/step - loss: 301.3762\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 122.7521\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 101.2478\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 101.2859\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 81.1313\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 84.0667\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 71.5514\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 80.1566\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 76.0769\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 82.5982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58b9f0e350>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Evaluate Model**\n",
        "   - Choose a holdout dataset used to evaluate model. Not the data used in training process.\n",
        "   - Calling function with the holdout dataset."
      ],
      "metadata": {
        "id": "YaCsnuR_tXur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mean squared error : mean of ( the sum of (squares of predicted value and actual value) )\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "2_r0svDz4o1F",
        "outputId": "b577d6c0-6ff3-4b2b-af01-2c9a77e1710b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 48.8836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48.88363265991211"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tunning\n",
        "   1. Learning Rate : Scalar used to train model via gradient descent. Get gradient step\n",
        "   2. Epochs : Total number of examples/ batch size training iterations.\n",
        "   3. Batch Size : Number of examples in batch.\n",
        "\n",
        "    - Training loss should steadily decrease, steeply at first, and then more slowly until the slope of the curve reaches or approaches zero.\n",
        "    - If the training loss does not converge, train for more epochs.\n",
        "    - If the training loss decreases too slowly, increase the learning rate. Note that setting the learning rate too high may also prevent training loss from converging.\n",
        "    - If the training loss varies wildly (that is, the training loss jumps around), decrease the learning rate.\n",
        "    - Lowering the learning rate while increasing the number of epochs or the batch size is often a good combination.\n",
        "    - Setting the batch size to a very small batch number can also cause instability. First, try large batch size values. Then, decrease the batch size until you see degradation.\n",
        "    - For real-world datasets consisting of a very large number of examples, the entire dataset might not fit into memory. In such cases, you'll need to reduce the batch size to enable a batch to fit into memory."
      ],
      "metadata": {
        "id": "W46916a3uvNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning Rate**"
      ],
      "metadata": {
        "id": "blfmc2gpxAwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# learning rate \n",
        "learning_rate = 0.1\n",
        "optimizer = RMSprop(learning_rate)   \n",
        "\n",
        "# compile model\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)  \n",
        "\n",
        "# fit model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=30, verbose = 1)\n",
        "\n",
        "# evaluate model\n",
        "print( 'The MSE value is: {}'.format(model.evaluate(X_test, y_test)) )"
      ],
      "metadata": {
        "id": "NHybwfz34o4r",
        "outputId": "ee4832e5-8675-4c9c-e48d-a08e061ec67b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 9724.5742\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 582.0069\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 555.8216\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 521.9397\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 483.8689\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 444.7491\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 406.9054\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 371.2612\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 337.6587\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 306.2268\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 271.3605\n",
            "The MSE value is: 271.36053466796875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Epochs**"
      ],
      "metadata": {
        "id": "q8RNW42UxE9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# learning rate \n",
        "learning_rate = 0.1\n",
        "optimizer = RMSprop(learning_rate)   \n",
        "\n",
        "# compile model\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)  \n",
        "\n",
        "# fit model\n",
        "# epochs = 100\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=30, verbose = 1)\n",
        "\n",
        "# evaluate model\n",
        "print( 'The MSE value is: {}'.format(model.evaluate(X_test, y_test)) )"
      ],
      "metadata": {
        "id": "5RwbXpQowg85",
        "outputId": "c3fd0837-0ba2-4181-c7a9-af6202705572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 2ms/step - loss: 23396.1465\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 201.6169\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 170.4288\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 139.8270\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 156.8873\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 225.7507\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 302.6345\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 174.3808\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 303.7362\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 170.9729\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 170.2001\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 148.9080\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 212.7323\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 299.8943\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 181.5383\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 104.5770\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.4909\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.3166\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.6096\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.1320\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.7828\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.4245\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.8433\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.2847\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.6685\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.9003\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.3227\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 95.5341\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.7820\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.5452\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.4010\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.7471\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.9352\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.6158\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.9391\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.8243\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.9244\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.5648\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.9445\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.9433\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.1537\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.5492\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.3398\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.3669\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.3881\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.2109\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.8853\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.6478\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.5075\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.0112\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 95.2063\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.9667\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.7863\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.8643\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.4945\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.6783\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.8080\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.6915\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.9131\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.5581\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.7310\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.7121\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.2695\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.1406\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.3153\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.2033\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 92.6707\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0475\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9874\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.1528\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.5531\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.4845\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.3464\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.2601\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.2936\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.2392\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.7745\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.6855\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.7965\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.4326\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.9542\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.5789\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.5001\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.0947\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.2112\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.9927\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.4802\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.5449\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.0813\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.4246\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.9439\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.7261\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.2149\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.6495\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.5598\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.3967\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.7040\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0229\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.0077\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.2685\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 73.4868\n",
            "The MSE value is: 73.48677825927734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "optimizer = RMSprop(0.1)    # 0.1 is the learning rate\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # Compile the model\n",
        "\n",
        "# fit the model \n",
        "# batch size is 40\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=40, verbose = 1)\n",
        "\n",
        "# evaluate the model\n",
        "print('The MSE value is: ', model.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "id": "7Wx3VhcvwheV",
        "outputId": "8f7198cc-ebfc-4c0b-822f-6a8b7595d846",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 102344.7500\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 3453.4258\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 1534.6553\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 918.4926\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 667.4976\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 472.3442\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 340.3143\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 219.0995\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 122.5397\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 98.4063\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f58b9ea19e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 103.1181\n",
            "The MSE value is:  103.1180648803711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Make Prediction**\n",
        "   - Calling function to make a prediction of a class label/probability/numerical value"
      ],
      "metadata": {
        "id": "HkEajZqe13TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Testing_set_boston.csv\")\n",
        "\n",
        "# prediction\n",
        "model.predict(df1)"
      ],
      "metadata": {
        "id": "1fig5zo-whkT",
        "outputId": "771a9d26-fe32-4bc3-d610-b2f41bb29b7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14.060397 ],\n",
              "       [20.16377  ],\n",
              "       [17.10065  ],\n",
              "       [18.210636 ],\n",
              "       [16.597511 ],\n",
              "       [14.724353 ],\n",
              "       [12.480709 ],\n",
              "       [12.217047 ],\n",
              "       [17.676708 ],\n",
              "       [14.718193 ],\n",
              "       [11.631658 ],\n",
              "       [14.042578 ],\n",
              "       [ 4.8801556],\n",
              "       [16.236353 ],\n",
              "       [13.625102 ],\n",
              "       [18.470617 ],\n",
              "       [ 8.148098 ],\n",
              "       [12.423615 ],\n",
              "       [24.015396 ],\n",
              "       [15.612503 ],\n",
              "       [18.214302 ],\n",
              "       [19.518074 ],\n",
              "       [10.479654 ],\n",
              "       [13.4274235],\n",
              "       [14.498215 ],\n",
              "       [14.861399 ],\n",
              "       [17.75426  ],\n",
              "       [ 4.3694134],\n",
              "       [11.907473 ],\n",
              "       [15.254413 ],\n",
              "       [13.13257  ],\n",
              "       [15.582851 ],\n",
              "       [14.297354 ],\n",
              "       [17.242373 ],\n",
              "       [14.718104 ],\n",
              "       [ 9.26563  ],\n",
              "       [14.797251 ],\n",
              "       [14.688562 ],\n",
              "       [13.781407 ],\n",
              "       [17.705524 ],\n",
              "       [14.277737 ],\n",
              "       [16.49492  ],\n",
              "       [24.370396 ],\n",
              "       [18.001411 ],\n",
              "       [14.562223 ],\n",
              "       [16.152657 ],\n",
              "       [10.851566 ],\n",
              "       [17.977587 ],\n",
              "       [17.628212 ],\n",
              "       [17.379288 ],\n",
              "       [14.90183  ],\n",
              "       [17.678017 ],\n",
              "       [11.9991455],\n",
              "       [15.879484 ],\n",
              "       [17.619463 ],\n",
              "       [20.061739 ],\n",
              "       [16.354313 ],\n",
              "       [23.343016 ],\n",
              "       [15.176779 ],\n",
              "       [15.901882 ],\n",
              "       [18.145927 ],\n",
              "       [24.579842 ],\n",
              "       [17.74816  ],\n",
              "       [13.1370125],\n",
              "       [23.916595 ],\n",
              "       [10.800101 ],\n",
              "       [15.697159 ],\n",
              "       [18.95819  ],\n",
              "       [23.475039 ],\n",
              "       [ 3.369708 ],\n",
              "       [15.0284   ],\n",
              "       [18.82963  ],\n",
              "       [10.360228 ],\n",
              "       [24.911308 ],\n",
              "       [16.862051 ],\n",
              "       [ 8.596399 ],\n",
              "       [14.15173  ],\n",
              "       [24.233437 ],\n",
              "       [14.008344 ],\n",
              "       [15.204678 ],\n",
              "       [18.729969 ],\n",
              "       [12.864786 ],\n",
              "       [24.790546 ],\n",
              "       [14.313365 ],\n",
              "       [12.930792 ],\n",
              "       [14.492491 ],\n",
              "       [13.547005 ],\n",
              "       [16.367128 ],\n",
              "       [18.350475 ],\n",
              "       [13.229092 ],\n",
              "       [15.974711 ],\n",
              "       [ 4.8306704],\n",
              "       [13.4708805],\n",
              "       [15.744096 ],\n",
              "       [17.082436 ],\n",
              "       [13.423534 ],\n",
              "       [15.69781  ],\n",
              "       [ 4.9537315],\n",
              "       [ 4.691209 ],\n",
              "       [ 4.9451246],\n",
              "       [14.895368 ],\n",
              "       [16.997692 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}